<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Project page for ICLR 2024 spotlight">
  <meta property="og:title" content="Beyond Worst-case Attacks: Robust RL with Adaptive Defense via Non-dominated Policies"/>
  <meta property="og:description" content="Project page for ICLR 2024 spotlight"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/framework.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Beyond Worst-case Attacks: Robust RL with Adaptive Defense via Non-dominated Policies">
  <meta name="twitter:description" content="Project page for ICLR 2024 spotlight">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/framework.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="robust reinforcement learning; beyond worse-case">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Beyond Worst-case Attacks: Robust RL with Adaptive Defense via Non-dominated Policies</title>
  <link rel="icon" type="image/x-icon" href="static/images/agent.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>
  <script type="text/javascript"
    src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="text-content" style="text-align: left; margin-bottom: 10px;">
          <p><a href="index.html" target="_self">[PC]</a> <a href="m_index.html" target="_self">[Mobile]</a>
        </p>
        </div>
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Beyond Worst-case Attacks: Robust RL with Adaptive Defense via Non-dominated Policies</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="" target="_blank">Xiangyu Liu</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="" target="_blank">Chenghao Deng</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://ycsun2017.github.io" target="_blank">Yanchao Sun</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://cheryyun.github.io" target="_blank">Yongyuan Liang</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://furong-huang.com" target="_blank">Furong Huang</a><sup>1</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">University of Maryland, College Park<sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;JP Morgan AI Research<sup>2</sup><br>ICLR 2024 spotlight</span>
                    <span class="eql-cntrb"><small><small><small><br><sup>*</sup>Equal Contribution</small></small></small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://openreview.net/forum?id=DFTHW0MyiW" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!--
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>
                  -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/umd-huang-lab/PROTECTED.git" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!--framework-->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">      
      <!-- First Image with adjusted size and centered -->
      <div style="margin-bottom: 40px; text-align: center;"> <!-- Adjust the margin as needed -->
        <img src="static/images/framework.png" alt="Description of First Image" style="width: 900px; display: block; margin: auto;"/> <!-- Adjust width as needed -->
        <!-- Caption with constrained width -->
        <div style="max-width: 850px; margin: auto;"> <!-- Adjust max-width as needed -->
          <h2 class="subtitle has-text-centered">
            <small>
            Framework of <b>PROTECTED</b>: <b>Pr</b>e-training N<b>o</b>n-domina<b>te</b>d Poli<b>c</b>ies <b>t</b>owards Onlin<b>e</b> A<b>d</b>aptation
            </small>
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<!--<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section>-->
<!-- End teaser video -->


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In light of the burgeoning success of reinforcement learning (RL) in diverse real-world applications, considerable focus has been directed towards ensuring RL policies are robust to adversarial attacks during test time. Current approaches largely revolve around solving a minimax problem to prepare for potential worst-case scenarios. 
            While effective against strong attacks, these methods often compromise performance in the absence of attacks or the presence of only weak attacks. 
            To address this, we study policy robustness under the well-accepted state-adversarial attack model, extending our focus beyond merely worst-case attacks. We first formalize this task at test time as a regret minimization problem and establish its intrinsic difficulty in achieving sublinear regret when the baseline policy is from a general continuous policy class, $\Pi$. 
            This finding prompts us to <b><i>refine</i></b> the baseline policy class  prior to test time, aiming for efficient adaptation within a compact, finite policy class $\Pi$, which can resort to an adversarial bandit subroutine. In light of the importance of a finite and compact $\tilde{\Pi}$, we propose a novel training-time algorithm to iteratively discover <b><i>non-dominated policies</i></b>, forming a near-optimal and minimal $\tilde{\Pi}$
, thereby ensuring both robustness and test-time efficiency. 
            Empirical validation on the Mujoco corroborates the superiority of our approach in terms of natural and robust performance, as well as adaptability to various attack scenarios.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Motivation -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h3 class="title is-4">Motivation</h3>
       <div id="results-carousel" class="carousel results-carousel" style="text-align: center;">
        <div class="item" style="text-align: center;"> <!-- Centering the content -->
          <!-- First image resized -->
          <img src="static/images/motivation1.png" alt="worst-case" style="width: 40%; display: block; margin: auto;"/> <!-- Adjust width as needed -->
          <h2 class="subtitle has-text-centered">
              Existing approaches aimed at principled defense often prioritize robustness against <b>worst-case</b> attacks.
            </h2>
        </div>
        <div class="item" style="text-align: center;"> <!-- Centering the content -->
          <!-- Second image resized -->
          <img src="static/images/motivation2.png" alt="beyond worst-case" style="width: 40%; display: block; margin: auto;"/> <!-- Adjust width as needed -->
          <h2 class="subtitle has-text-centered">
              But this focus can lead to suboptimal performance when RL policies are subjected to <b>no</b> or <b>weak</b> attacks during test time.
          </h2>
        </div>
      </div>
      <div class="contegit nt is-centered has-text-justified" style="text-align: center">
      <p style="font: size 72px; text-align: center">
          <br> <br/>
          <i>"Is it possible to develop a comprehensive framework that enhances the performance of the victim against non-worst-case attacks, while maintaining robustness against worst-case scenarios?"</i>
          <br> <br/>
      </p>
      </div>
  </div>
</section>
<!-- End image carousel -->

<!-- Online Adaptation -->
<section class="hero teaser is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h3 class="title is-4">Test-time Online Adaptation</h3>
      <div class="text-content" style="text-align: left; margin-bottom: 30px;">
        <p>Instead of employing a static victim policy, we propose adaptively selecting policies based on online reward feedback during test time. 
          Although the sublinear regret is not guaranteed in the broader policy class $\Pi$, it is achievable in a smaller, finite but refined policy class $\tilde{\Pi}$. 
      </p>
      </div>
      <div style="margin-bottom: 40px; text-align: center;">
        <div class="item item-video1" style="text-align: center;">
          <video poster="" id="video1" width="60%" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/adaptation1.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
      <div class="text-content" style="text-align: left; margin-bottom: 30px;">
        <p>Given such a refined policy class, we can perform online adaptation with adversarial bandit algorithm such as EXP3, which maintains a meta-policy during online adaptation and adjusts the weight of each policy based on the online reward feedback.
      </p>
      </div>
      <div class="item" style="margin-bottom: 40px; text-align: center;"> <!-- Centering the content -->
        <!-- Second image resized -->
        <img src="static/images/alg1.png" alt="alg1" style="width: 80%; display: block; margin: auto;"/> <!-- Adjust width as needed -->
      </div>
    </div>  
  </div>
</div>
</section>
<!-- Online Adaptation -->

<!-- Iterative Discovery -->
<section class="hero teaser is-small">
  <div class="hero-body">
    <div class="container">
      <h3 class="title is-4">Iterative Discovery in Pre-training</h3>
      <div class="text-content" style="text-align: left; margin-bottom: 30px;">
        <p>While there is a trade-off between optimality (the gap of maximum rewards in the original policy class $\Pi$ and the refined policy class $\tilde{\Pi}$) and efficiency (the cardinality of the refined policy class $|\tilde{\Pi}|$), it is proved that a zero gap is achivable with a finite refined policy class. 
          But this finite policy class can be still relatively large.
          To effectively reduce the cardinality of $\tilde{\Pi}$, we propose an iterative pre-training approach to construct $\tilde{\Pi}$.
      </p>
      </div>
      <div style="margin-bottom: 40px; text-align: center;">
        <div class="item item-video1" style="text-align: center;">
          <video poster="" id="video1" width="50%" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/pretraining1.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
      <div class="text-content" style="text-align: left; margin-bottom: 30px;">
        <p>For each iteration, a new <i>non-dominated</i> policy (red dot), whose reward aginst at least one attack outperforms all meta-policies in $\tilde{\Pi}$, is added to $\tilde{\Pi}$.
          This process effectively removes those redundant <i>dominated</i> policies (the orange area) while maintaining the optimality of $\tilde{\Pi}$.

      </p>
      </div>
      <div class="item" style="margin-bottom: 40px; text-align: center;"> <!-- Centering the content -->
        <!-- Second image resized -->
        <img src="static/images/alg2.png" alt="alg2" style="width: 80%; display: block; margin: auto;"/> <!-- Adjust width as needed -->
      </div>
    </div>  
  </div>
</div>
</section>
<!-- Iterative Discovery -->

<!-- Experimental Results -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h3 class="title is-4">Experimental Results</h3>
      <div class="text-content" style="text-align: left; margin-bottom: 30px;">
        <p>Our methods yield considerably higher natural rewards and consistently enhanced robustness against a spectrum of attacks in various Mujoco environments.
      </p>
      </div>
      <div style="margin-bottom: 40px; text-align: center;"> <!-- Adjust the margin as needed -->
        <img src="static/images/experiments1.png" alt="Description of First Image" style="width: 700px; display: block; margin: auto;"/> <!-- Adjust width as needed -->
        <!-- Caption with constrained width -->
        <div style="max-width: 850px; margin: auto;"> <!-- Adjust max-width as needed -->
          <h2 class="subtitle has-text-centered">
          </h2>
        </div>
      </div>

      <div class="text-content" style="text-align: left; margin-bottom: 30px;">
        <p>Moreover, in the scenarios where the attacker can exhibit dynamic behavior, the best policy within non-dominated policy class $\tilde{\Pi}$ can be identified by EXP3 rapidly and reliably.
      </p>
      </div>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item" style="text-align: center;"> <!-- Centering the content -->
          <img src="static/images/plot/periodic_2_sub.png" alt="period1000" style="width: 40%; display: block; margin: auto;"/> <!-- Adjust width as needed -->
          <p class="subtitle has-text-centered">
            <small>
              Periodical attack, $T=1000$.
            </small>
          </p>
        </div>
        <div class="item" style="text-align: center;"> <!-- Centering the content -->
          <img src="static/images/plot/periodic_10_sub.png" alt="period200" style="width: 40%; display: block; margin: auto;"/> <!-- Adjust width as needed -->
          <p class="subtitle has-text-centered">
            <small>
              Periodical attack, $T=200$.
            </small>
          </p>
        </div>
        <div class="item" style="text-align: center;"> <!-- Centering the content -->
          <img src="static/images/plot/prob_switch_p0.4_sub.png" alt="prob0.4" style="width: 40%; display: block; margin: auto;"/> <!-- Adjust width as needed -->
          <p class="subtitle has-text-centered">
            <small>
              Problistic switching attack, $p=0.4$.
            </small>
          </p>
        </div>
        <div class="item" style="text-align: center;"> <!-- Centering the content -->
          <img src="static/images/plot/prob_switch_p0.8_sub.png" alt="prob0.8" style="width: 40%; display: block; margin: auto;"/> <!-- Adjust width as needed -->
          <p class="subtitle has-text-centered">
            <small>
              Problistic switching attack, $p=0.8$.
            </small>
          </p>
        </div>
      </div>
    </div>  
  </div>
</div>
</section>
<!-- Experimental Results -->


<!-- Paper poster -->
<!--
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
-->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{
        liu2024beyond,
        title={Beyond Worst-case Attacks: Robust {RL} with Adaptive Defense via Non-dominated Policies},
        author={Xiangyu Liu and Chenghao Deng and Yanchao Sun and Yongyuan Liang and Furong Huang},
        booktitle={The Twelfth International Conference on Learning Representations},
        year={2024},
        url={https://openreview.net/forum?id=DFTHW0MyiW}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
